import { NextRequest } from 'next/server';
import { generateResponse } from '@/lib/gemini';
import { 
  getDb,
  getChatMessages,
  addChatMessage,
  updateSessionTimestamp,
  trackConversationContext,
  createSessionSummary,
  trackGlobalMemory,
  getSessionContexts
} from '@/lib/db';
import { analyzeQuery } from '@/lib/queryProcessor';
import { retrieveSmartContext, detectFollowUpWithAI } from '@/lib/smartRetrieval';
import { createClient } from '@supabase/supabase-js';
import { 
  isComplexQuery, 
  performMultiHopReasoning, 
  formatMultiHopResponse 
} from '@/lib/multiHopReasoning';
import {
  analyzeConversationContext,
  generateSessionSummary as generateContextSummary,
  extractTopicsFromMessage
} from '@/lib/contextAnalyzer';

export const dynamic = 'force-dynamic';
export const runtime = 'nodejs';

const supabaseAdmin = createClient(
  process.env.SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

/**
 * âœ… Detect document language from Supabase embeddings
 */
async function detectDocumentLanguage(documentId: string): Promise<'ar' | 'en'> {
  try {
    console.log(`ğŸ” Detecting language for document: ${documentId}`);

    const { data, error } = await supabaseAdmin
      .from('embeddings')
      .select('chunk_text')
      .eq('document_id', documentId)
      .limit(20);

    if (error) {
      console.error('âš ï¸ Error fetching embeddings:', error);
      return 'ar';
    }

    if (!data || data.length === 0) {
      console.warn('âš ï¸ No embeddings found for document, defaulting to Arabic');
      return 'ar';
    }

    const contentChunks = data.filter(row => {
      const text = row.chunk_text.toLowerCase();
      return !(
        text.includes('table of contents') ||
        text.includes('chapter') && text.length < 100 ||
        /^page \d+/i.test(text) ||
        text === 'ÙÙŠ Ø±Ø­Ø§Ø¨ Ø£Ù…Ø±ÙŠÙƒØ§'
      );
    });

    const chunksToAnalyze = contentChunks.length > 0 ? contentChunks : data;
    const combinedText = chunksToAnalyze.map(row => row.chunk_text).join(' ');
    
    const arabicChars = (combinedText.match(/[\u0600-\u06FF]/g) || []).length;
    const totalChars = combinedText.replace(/\s/g, '').length;

    const arabicRatio = arabicChars / totalChars;
    const detectedLang = arabicRatio > 0.3 ? 'ar' : 'en';

    console.log(`   âœ… Language detected: ${detectedLang} (${(arabicRatio * 100).toFixed(1)}% Arabic, analyzed ${chunksToAnalyze.length} chunks)`);

    return detectedLang;

  } catch (error) {
    console.error('âŒ Error in detectDocumentLanguage:', error);
    return 'ar';
  }
}

/**
 * âœ… Detect user's query language
 */
function detectQueryLanguage(query: string): 'ar' | 'en' {
  const arabicChars = (query.match(/[\u0600-\u06FF]/g) || []).length;
  const totalChars = query.replace(/\s/g, '').length;
  const arabicRatio = arabicChars / totalChars;
  
  return arabicRatio > 0.3 ? 'ar' : 'en';
}

/**
 * âœ… Detect languages for multiple documents
 */
async function detectMultipleDocumentLanguages(documentIds: string[]): Promise<{
  primary: 'ar' | 'en';
  languages: Map<string, 'ar' | 'en'>;
  isMultilingual: boolean;
}> {
  const languages = new Map<string, 'ar' | 'en'>();
  
  for (const docId of documentIds) {
    const lang = await detectDocumentLanguage(docId);
    languages.set(docId, lang);
  }
  
  const arabicCount = Array.from(languages.values()).filter(l => l === 'ar').length;
  const englishCount = languages.size - arabicCount;
  
  const primary = arabicCount >= englishCount ? 'ar' : 'en';
  const isMultilingual = arabicCount > 0 && englishCount > 0;
  
  console.log(`ğŸŒ Multi-document language analysis:
   - Total documents: ${documentIds.length}
   - Arabic: ${arabicCount}
   - English: ${englishCount}
   - Primary: ${primary}
   - Multilingual: ${isMultilingual}`);
  
  return { primary, languages, isMultilingual };
}

export async function POST(req: NextRequest) {
  const encoder = new TextEncoder();
  const stream = new TransformStream();
  const writer = stream.writable.getWriter();

  (async () => {
    try {
      const { 
        message, 
        query,
        sessionId, 
        bookId, 
        bookTitle, 
        bookPage,
        extractedText,
        documentIds,
        correctSpelling = false,
        aggressiveCorrection = false,
        customPrompt,
        enableMultiHop = false,
        preferredModel, 
        useReranking = true,
        useKeywordSearch = false
      } = await req.json();

      const userMessage = message || query;

      console.log('ğŸ“š Reader Chat:', {
        sessionId,
        hasMessage: !!userMessage,
        hasCorpus: documentIds?.length > 0,
        corpusCount: documentIds?.length || 0,
        enableMultiHop,
        preferredModel,
        useKeywordSearch
      });

      if (!userMessage) {
        await writer.write(encoder.encode('Error: Missing message or query'));
        await writer.close();
        return;
      }

      // âœ… STEP 1: Load conversation history (if session exists)
      let history: Array<{ role: string; content: string; created_at: string }> = [];
      if (sessionId) {
        const db = getDb();
        history = db.prepare(`
          SELECT role, content, created_at
          FROM chat_messages 
          WHERE session_id = ? 
          ORDER BY created_at DESC
          LIMIT 10
        `).all(sessionId) as Array<{ role: string; content: string; created_at: string }>;
        
        history.reverse();
        console.log(`ğŸ“œ Loaded ${history.length} previous messages`);
      }

      // âœ… STEP 1.5: AI-POWERED FOLLOW-UP DETECTION
      const conversationHistory = history.map(msg => ({
        role: msg.role,
        content: msg.content
      }));

      const followUpDetection = await detectFollowUpWithAI(userMessage, conversationHistory);

      console.log(`ğŸ” Reader Mode Follow-up Analysis:`, {
        isFollowUp: followUpDetection.isFollowUp,
        confidence: followUpDetection.confidence,
        reason: followUpDetection.reason,
        needsRetrieval: followUpDetection.needsNewRetrieval
      });

      // âœ… STEP 2: Analyze conversation context (every 3 messages)
      if (sessionId && history.length > 0 && history.length % 3 === 0) {
        console.log('ğŸ§  Analyzing reader chat context...');
        
        const queryLanguage = detectQueryLanguage(userMessage);

        try {
          const context = await analyzeConversationContext(conversationHistory, queryLanguage);
          
          if (context.topics.length > 0) {
            for (const topic of context.topics.slice(0, 3)) {
              const contextId = `ctx-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
              trackConversationContext({
                id: contextId,
                sessionId,
                topic,
                keywords: context.keywords,
                entities: context.entities,
                relevanceScore: 0.8
              });
            }
          }

          if (context.mainTheme) {
            const memoryId = `mem-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
            trackGlobalMemory({
              id: memoryId,
              topic: context.mainTheme,
              context: `Book: ${bookTitle || 'Unknown'}, Page: ${bookPage || 'N/A'}, Intent: ${context.userIntent}`,
              sessionId
            });
          }

          console.log('âœ… Reader context tracked');
        } catch (error) {
          console.error('âš ï¸ Context analysis failed:', error);
        }
      }

      // âœ… STEP 3: Generate summary (every 10 messages)
      if (sessionId && history.length > 0 && history.length % 10 === 0) {
        console.log('ğŸ“ Generating reader session summary...');
        
        try {
          const queryLanguage = detectQueryLanguage(userMessage);

          const summaryResult = await generateContextSummary(conversationHistory, queryLanguage);
          
          const summaryId = `sum-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
          createSessionSummary({
            id: summaryId,
            sessionId,
            summary: summaryResult.summary,
            keyPoints: summaryResult.keyPoints,
            messageCount: history.length
          });

          console.log('âœ… Reader summary created');
        } catch (error) {
          console.error('âš ï¸ Summary generation failed:', error);
        }
      }

      // âœ… STEP 4: Route to appropriate handler (NO MESSAGE SAVING HERE)
      if (documentIds && documentIds.length > 0) {
        console.log('ğŸ”„ Using corpus retrieval for Reader Chat');
        await handleCorpusQuery(
          writer, 
          encoder, 
          userMessage, 
          documentIds, 
          extractedText, 
          customPrompt,
          enableMultiHop,
          sessionId,
          history,
          bookTitle,
          bookPage,
          preferredModel,
          useKeywordSearch ? false : useReranking,
          useKeywordSearch,
          followUpDetection
        );
      } 
      else if (sessionId) {
        console.log('ğŸ’¬ Using general chat with history for Reader Chat');
        await handleGeneralChat(writer, encoder, userMessage, sessionId, extractedText, bookPage, history, preferredModel);
      }
      else {
        console.log('ğŸ“ Using simple query response');
        await handleSimpleQuery(writer, encoder, userMessage, extractedText, preferredModel);
      }

      await writer.close();

    } catch (error) {
      console.error('âŒ Reader chat error:', error);
      try {
        const errorMsg = error instanceof Error ? error.message : 'Unknown error';
        await writer.write(encoder.encode(`Error: ${errorMsg}`));
        await writer.close();
      } catch {}
    }
  })();

  return new Response(stream.readable, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}

// ==================== CORPUS QUERY HANDLER (WITH OPTIONAL MULTI-HOP) ====================
async function handleCorpusQuery(
  writer: WritableStreamDefaultWriter,
  encoder: TextEncoder,
  query: string,
  documentIds: string[],
  extractedText?: string,
  customPrompt?: string,
  enableMultiHop: boolean = false,
  sessionId?: string,
  history?: Array<{ role: string; content: string }>,
  bookTitle?: string,
  bookPage?: number,
  preferredModel?: string,
  useReranking: boolean = true,
  useKeywordSearch: boolean = false,
  followUpDetection?: { isFollowUp: boolean; confidence: number; reason: string; needsNewRetrieval: boolean }
) {
  let conversationContextString = '';
  let contextualPromptAddition = '';
  
  if (sessionId && history && history.length > 0) {
    const db = getDb();
    const contexts = getSessionContexts(sessionId) as Array<{
      topic: string;
      keywords: string;
      mention_count: number;
    }>;

    if (contexts.length > 0) {
      const recentTopics = contexts
        .slice(0, 3)
        .map(c => c.topic)
        .join(', ');
      
      const queryLanguage = detectQueryLanguage(query);
      contextualPromptAddition = queryLanguage === 'ar'
        ? `\n\nğŸ“‹ **Ø§Ù„ÙˆØ¹ÙŠ Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚:**\nØ§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ØªÙŠ Ù†Ø§Ù‚Ø´Ù†Ø§Ù‡Ø§ Ù…Ø¤Ø®Ø±Ø§Ù‹: ${recentTopics}\n`
        : `\n\nğŸ“‹ **Context Awareness:**\nRecent topics we've discussed: ${recentTopics}\n`;
    }

    const recentHistory = history.slice(-4);
    if (recentHistory.length > 0) {
      const queryLanguage = detectQueryLanguage(query);
      conversationContextString = queryLanguage === 'ar'
        ? '\n\nğŸ“œ **Ù…Ø­Ø§Ø¯Ø«ØªÙ†Ø§ Ø§Ù„Ø£Ø®ÙŠØ±Ø©:**\n'
        : '\n\nğŸ“œ **Recent conversation:**\n';
      
      recentHistory.forEach(msg => {
        const label = msg.role === 'user' 
          ? (queryLanguage === 'ar' ? 'Ø£Ù†Øª' : 'You')
          : (queryLanguage === 'ar' ? 'Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯' : 'Assistant');
        conversationContextString += `**${label}:** ${msg.content.substring(0, 100)}${msg.content.length > 100 ? '...' : ''}\n\n`;
      });
    }
  }

  const { primary: documentLanguage, languages: docLanguages, isMultilingual } = 
    await detectMultipleDocumentLanguages(documentIds);

  const queryLanguage = detectQueryLanguage(query);
  console.log(`ğŸ—£ï¸ Query language: ${queryLanguage}`);

  const responseLanguage = queryLanguage;
  console.log(`ğŸ’¬ Response will be in: ${responseLanguage}`);

  const requiresMultiHop = enableMultiHop && isComplexQuery(query);
  
  if (requiresMultiHop) {
    console.log('ğŸ§  Complex query detected - activating multi-hop reasoning');
    
    try {
      const multiHopResult = await performMultiHopReasoning(
        query,
        documentIds,
        docLanguages,
        4,
        responseLanguage
      );
      
      let conversationPrefix = '';
      if (conversationContextString) {
        conversationPrefix = responseLanguage === 'ar'
          ? `ğŸ’­ **Ø§Ø³ØªÙƒÙ…Ø§Ù„Ø§Ù‹ Ù„Ù…Ø­Ø§Ø¯Ø«ØªÙ†Ø§:**\n\n${conversationContextString}\n\n---\n\n`
          : `ğŸ’­ **Continuing our conversation:**\n\n${conversationContextString}\n\n---\n\n`;
      }
      
      const formattedResponse = conversationPrefix + formatMultiHopResponse(multiHopResult, responseLanguage);
      await writer.write(encoder.encode(formattedResponse));
      
      console.log('âœ… Multi-hop response complete');
      return;
      
    } catch (error) {
      console.error('âŒ Multi-hop reasoning failed, falling back to standard retrieval:', error);
    }
  }

  console.log(enableMultiHop ? 'ğŸ“– Using standard retrieval (fallback)' : 'ğŸ“– Using standard retrieval strategy');
  
  const contextParts: string[] = [];

  // âœ… Perform query analysis
  const queryAnalysis = await analyzeQuery(query, documentLanguage);
  
  // âœ… ADD follow-up info to query analysis
  if (followUpDetection) {
    queryAnalysis.isFollowUp = followUpDetection.isFollowUp;
    queryAnalysis.followUpConfidence = followUpDetection.confidence;
    queryAnalysis.needsNewRetrieval = followUpDetection.needsNewRetrieval;
  }

  console.log('ğŸ” Query Analysis:', {
    original: queryAnalysis.originalQuery,
    translated: queryAnalysis.translatedQuery,
    type: queryAnalysis.queryType,
    keywords: queryAnalysis.keywords,
    isMultiDoc: queryAnalysis.isMultiDocumentQuery,
    isFollowUp: queryAnalysis.isFollowUp,
    needsRetrieval: queryAnalysis.needsNewRetrieval
  });

  if (extractedText) {
    const extractLabel = responseLanguage === 'ar' 
      ? '**ğŸ“„ Ù†Øµ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**'
      : '**ğŸ“„ Current Page Text:**';
    contextParts.push(`${extractLabel}\n${extractedText}`);
  }

  // âœ… SMART RETRIEVAL DECISION
  let retrievedContext = '';
  let processedChunks: any[] = [];

  if (queryAnalysis.needsNewRetrieval || !queryAnalysis.isFollowUp) {
    console.log('ğŸ“š Performing new retrieval for reader mode...');
    
    const { chunks, strategy, confidence } = await retrieveSmartContext(
      queryAnalysis, 
      documentIds, 
      useReranking, 
      useKeywordSearch
    );
    
    console.log(`ğŸ“Š Retrieval Results:
   - Strategy: ${strategy}
   - Chunks found: ${chunks.length}
   - Confidence: ${(confidence * 100).toFixed(1)}%
   - Keyword Search: ${useKeywordSearch ? 'enabled' : 'disabled'}`);

    processedChunks = chunks;
  } else {
    console.log('ğŸ’¬ Follow-up detected - reusing conversation context');
    
    // Use previous context from history
    if (history && history.length > 0) {
      retrievedContext = history
        .filter(msg => msg.role === 'assistant')
        .slice(-2)
        .map(msg => msg.content)
        .join('\n\n---\n\n');
      
      contextParts.push(`**${responseLanguage === 'ar' ? 'Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚' : 'Previous Context'}:**\n\n${retrievedContext}`);
    }
  }

  if (processedChunks.length > 0) {
    const chunksByDocument = new Map<string, any[]>();
    
    processedChunks.forEach(chunk => {
      if (!chunksByDocument.has(chunk.document_id)) {
        chunksByDocument.set(chunk.document_id, []);
      }
      chunksByDocument.get(chunk.document_id)!.push(chunk);
    });

    console.log(`ğŸ“š Chunks distributed across ${chunksByDocument.size} document(s)`);

    const isArabic = responseLanguage === 'ar';
    
    const documentContexts = Array.from(chunksByDocument.entries()).map(([docId, docChunks], docIndex) => {
      const docNumber = docIndex + 1;
      const docLang = docLanguages.get(docId);
      const langLabel = docLang === 'ar' ? 'Ø¹Ø±Ø¨ÙŠ' : 'English';
      
      const docHeader = isArabic
        ? `## ğŸ“˜ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© ${docNumber} (${langLabel})`
        : `## ğŸ“˜ Document ${docNumber} (${langLabel})`;
      
      const pageGroups = new Map<number, any[]>();
      docChunks.forEach(chunk => {
        if (!pageGroups.has(chunk.page_number)) {
          pageGroups.set(chunk.page_number, []);
        }
        pageGroups.get(chunk.page_number)!.push(chunk);
      });
      
      const pageEntries = Array.from(pageGroups.entries())
        .sort((a, b) => {
          if (useKeywordSearch) {
            return a[0] - b[0];
          } else {
            const maxSimA = Math.max(...a[1].map(c => c.similarity || 0));
            const maxSimB = Math.max(...b[1].map(c => c.similarity || 0));
            return maxSimB - maxSimA;
          }
        })
        .slice(0, useKeywordSearch ? 50 : 10);
      
      const pagesText = pageEntries
        .map(([pageNum, pageChunks]) => {
          const bestSimilarity = Math.max(...pageChunks.map(c => c.similarity || 0));
          const matchedKeyword = pageChunks[0]?.matched_keyword;
          
          const relevanceIcon = useKeywordSearch 
            ? 'ğŸ”' 
            : (bestSimilarity >= 0.5 ? 'ğŸ¯' : bestSimilarity >= 0.4 ? 'âœ“' : 'ğŸ“„');
          
          const pageHeader = isArabic 
            ? `**${relevanceIcon} ØµÙØ­Ø© ${pageNum}${matchedKeyword ? ` (${matchedKeyword})` : ''}**`
            : `**${relevanceIcon} Page ${pageNum}${matchedKeyword ? ` (${matchedKeyword})` : ''}**`;
          
          const pageText = pageChunks.map(c => c.chunk_text).join('\n\n');
          return `${pageHeader}\n${pageText}`;
        })
        .join('\n\n---\n\n');
      
      return `${docHeader}\n\n${pagesText}`;
    }).join('\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n');

    const contextTitle = isArabic 
      ? '**ğŸ“š Ù…Ù‚Ø§Ø·Ø¹ Ø°Ø§Øª ØµÙ„Ø© Ù…Ù† Ø§Ù„ÙƒØªØ¨:**'
      : '**ğŸ“š Relevant Passages from the Books:**';

    contextParts.push(`${contextTitle}\n\n${documentContexts}`);

    if (isMultilingual) {
      const multilingualNote = isArabic
        ? '\n\nğŸ“– **Ù…Ù„Ø§Ø­Ø¸Ø©:** Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø© Ù…Ù† Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¨Ù„ØºØ§Øª Ù…Ø®ØªÙ„ÙØ© (Ø¹Ø±Ø¨ÙŠ ÙˆØ¥Ù†Ø¬Ù„ÙŠØ²ÙŠ).'
        : '\n\nğŸ“– **Note:** The displayed passages are from documents in different languages (Arabic and English).';
      contextParts.push(multilingualNote);
    }

    if (documentIds.length > 1 && queryAnalysis.isMultiDocumentQuery) {
      const comparisonInstruction = isArabic
        ? '\n\nâš ï¸ **ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:** Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ Ù…Ù‚Ø§Ø±Ù†. Ù‚Ø§Ø±Ù† ÙˆØ­Ù„Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©.'
        : '\n\nâš ï¸ **Important Instructions:** This is a comparative question. Compare and analyze information from ALL provided documents.';
      contextParts.push(comparisonInstruction);
    }

    const pageListNote = isArabic
      ? `\n\nâš ï¸ **Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©:** Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø£Ø¹Ù„Ø§Ù‡.`
      : `\n\nâš ï¸ **Important Note:** Answer only based on the available pages in the context above.`;
    
    contextParts.push(pageListNote);
  }

  const isArabic = responseLanguage === 'ar';
  
  let keywordSearchInstructions = '';
  if (useKeywordSearch) {
    keywordSearchInstructions = isArabic
      ? `\n\nğŸ”‘ **ÙˆØ¶Ø¹ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:**
   - Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØ·Ø§Ø¨Ù‚Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
   - **Ø§Ø°ÙƒØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©** Ù…Ø±ØªØ¨Ø© Ø­Ø³Ø¨ Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©
   - **Ù„Ø§ ØªÙ„Ø®Øµ - Ø§Ø°ÙƒØ± ÙƒÙ„ Ù…Ø§ ÙˆØ¬Ø¯ØªÙ‡**\n`
      : `\n\nğŸ”‘ **KEYWORD SEARCH MODE:**
   - Results contain EXACT MATCHES for the search terms
   - **List ALL occurrences found** in chronological order (by page)
   - **Do not summarize - list everything found**\n`;
  }
  
  const systemPrompt = isArabic
    ? `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¨Ø­Ø«ÙŠ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…ØªØ®ØµØµ ÙŠØªØ°ÙƒØ± Ø§Ù„Ø³ÙŠØ§Ù‚. Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ Markdown ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ.

ğŸ“‹ **Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:**

1. **Ø§Ù„ÙˆØ¹ÙŠ Ø¨Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:** ØªØ°ÙƒØ± Ù…Ø§ Ù†ÙˆÙ‚Ø´ Ø³Ø§Ø¨Ù‚Ø§Ù‹
2. **Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…:** Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø£Ø¯Ù†Ø§Ù‡
3. **Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ø¨Ø«Ù‚Ø©:** Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø±ÙØªÙƒ Ø¨Ø­Ø±ÙŠØ©
4. **Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø«Ù‚Ø©:** ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø±ÙŠØ©

${keywordSearchInstructions}${contextualPromptAddition}${customPrompt ? `\n**ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©:**\n${customPrompt}\n` : ''}`
    : `You are an accurate and specialized research assistant with conversational memory. Use Markdown formatting.

ğŸ“‹ **Core Guidelines:**

1. **Conversation Awareness:** Remember what was discussed previously
2. **Prioritize Provided Context:** Use passages below
3. **Integrate General Knowledge Confidently:** Use your knowledge freely
4. **Answer ALL Questions Confidently:** Avoid apologetic responses

${keywordSearchInstructions}${contextualPromptAddition}${customPrompt ? `\n**Additional Instructions:**\n${customPrompt}\n` : ''}`;

  const userQuery = queryAnalysis?.originalQuery || query;

  const fullPrompt = contextParts.length > 0
    ? `${systemPrompt}${conversationContextString}\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n${contextParts.join('\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n')}\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n**${isArabic ? 'Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…' : "User's Question"}:**\n${userQuery}\n\n**${isArabic ? 'Ø¥Ø¬Ø§Ø¨ØªÙƒ' : 'Your Answer'}:**`
    : `${systemPrompt}${conversationContextString}\n\n**${isArabic ? 'Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…' : "User's Question"}:**\n${userQuery}\n\n**${isArabic ? 'Ø¥Ø¬Ø§Ø¨ØªÙƒ' : 'Your Answer'}:**`;

  console.log('ğŸ¤– Querying Gemini with conversation awareness...');
  console.log(`ğŸ¯ Using model: ${preferredModel || 'default fallback'}`);

  const geminiResult = await generateResponse(fullPrompt, preferredModel);
  const geminiStream = geminiResult.stream;
  const modelUsed = geminiResult.modelUsed;
  
  console.log(`âœ… Response generated using: ${modelUsed}`);
  
  for await (const chunk of geminiStream) {
    const text = chunk.text();
    if (text) {
      await writer.write(encoder.encode(text));
    }
  }
  
  if (sessionId) {
    updateSessionTimestamp(sessionId);
  }
  
  console.log('âœ… Response complete');
}

// ==================== GENERAL CHAT HANDLER ====================
async function handleGeneralChat(
  writer: WritableStreamDefaultWriter,
  encoder: TextEncoder,
  message: string,
  sessionId: string,
  extractedText?: string,
  bookPage?: number,
  history?: Array<{ role: string; content: string }>,
  preferredModel?: string
) {
  let conversationContext = '';
  let contextualPromptAddition = '';
  
  if (history && history.length > 0) {
    const db = getDb();
    const contexts = getSessionContexts(sessionId) as Array<{
      topic: string;
      keywords: string;
    }>;

    if (contexts.length > 0) {
      const recentTopics = contexts.slice(0, 3).map(c => c.topic).join(', ');
      const queryLang = detectQueryLanguage(message);
      contextualPromptAddition = queryLang === 'ar'
        ? `\nğŸ“‹ **Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø©:** ${recentTopics}\n`
        : `\nğŸ“‹ **Topics discussed:** ${recentTopics}\n`;
    }

    conversationContext = history
      .map(msg => `${msg.role === 'user' ? 'User' : 'Assistant'}: ${msg.content}`)
      .join('\n\n');
  }

  let contextSection = '';
  if (extractedText) {
    contextSection = `\n\n---
**Context from Page ${bookPage || 'current page'}:**
${extractedText}
---`;
  }

  const queryLang = detectQueryLanguage(message);
  const langInstruction = queryLang === 'ar' 
    ? 'Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ†Ø³ÙŠÙ‚ Markdown. ØªØ°ÙƒØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.'
    : 'Respond in English using Markdown formatting. Remember the previous conversation.';

  const prompt = conversationContext
    ? `You are a helpful assistant with conversation memory. ${langInstruction}
${contextualPromptAddition}
${contextSection}

**Previous conversation:**
${conversationContext}

**User:** ${message}
**Assistant:**`
    : `You are a helpful assistant. ${langInstruction}
${contextSection}

**User:** ${message}
**Assistant:**`;

  const geminiResult = await generateResponse(prompt, preferredModel);
  const geminiStream = geminiResult.stream;
  
  for await (const chunk of geminiStream) {
    const text = chunk.text();
    if (text) {
      await writer.write(encoder.encode(text));
    }
  }
  
  updateSessionTimestamp(sessionId);
}

// ==================== SIMPLE QUERY HANDLER ====================
async function handleSimpleQuery(
  writer: WritableStreamDefaultWriter,
  encoder: TextEncoder,
  query: string,
  extractedText?: string,
  preferredModel?: string
) {
  const queryLang = detectQueryLanguage(query);
  const langInstruction = queryLang === 'ar' 
    ? 'Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ†Ø³ÙŠÙ‚ Markdown.'
    : 'Respond in English using Markdown formatting.';

  let contextSection = '';
  if (extractedText) {
    const contextLabel = queryLang === 'ar' ? 'Ø§Ù„Ø³ÙŠØ§Ù‚' : 'Context';
    contextSection = `\n\n---
**${contextLabel}:**
${extractedText}
---`;
  }

  const prompt = `You are a helpful assistant. ${langInstruction}
${contextSection}

**User:** ${query}
**Assistant:**`;

  const geminiResult = await generateResponse(prompt, preferredModel);
  const geminiStream = geminiResult.stream;
  
  for await (const chunk of geminiStream) {
    const text = chunk.text();
    if (text) {
      await writer.write(encoder.encode(text));
    }
  }
}